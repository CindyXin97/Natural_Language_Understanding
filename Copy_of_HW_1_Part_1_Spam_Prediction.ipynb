{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "py36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Copy of HW-1 Part 1. Spam Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Z8eeN5IW9q",
        "colab_type": "text"
      },
      "source": [
        "# Part 1.\n",
        "\n",
        "The deadline for Part 1 is **1:30 pm Feb 6th, 2020**.   \n",
        "You should submit a `.ipynb` file with your solutions to NYU Classes.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this part we will preprocess SMS Spam Collection Dataset and train a bag-of-words classifier (logistic regression) for spam detection. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZd0LJzbISPd",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "First, we download the SMS Spam Collection Dataset. The dataset is taken from [Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset/data#) and loaded to [Google Drive](https://drive.google.com/open?id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR) so that everyone can access it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvGErs2oHkWU",
        "colab_type": "code",
        "outputId": "bcfb8c85-6702-407e-e2a6-f94a23f76877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "!wget 'https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR' -O spam.csv "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-12 06:06:36--  https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.125.102, 108.177.125.100, 108.177.125.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.125.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-04-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ckhfknoatbku3mbamkojmiov212bp34u/1581487200000/08752484438609855375/*/1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-02-12 06:06:37--  https://doc-14-04-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ckhfknoatbku3mbamkojmiov212bp34u/1581487200000/08752484438609855375/*/1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR?e=download\n",
            "Resolving doc-14-04-docs.googleusercontent.com (doc-14-04-docs.googleusercontent.com)... 64.233.188.132, 2404:6800:4008:c06::84\n",
            "Connecting to doc-14-04-docs.googleusercontent.com (doc-14-04-docs.googleusercontent.com)|64.233.188.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 503663 (492K) [text/csv]\n",
            "Saving to: ‘spam.csv’\n",
            "\n",
            "spam.csv            100%[===================>] 491.86K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2020-02-12 06:06:37 (82.6 MB/s) - ‘spam.csv’ saved [503663/503663]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcHV1lUwtH-n",
        "colab_type": "code",
        "outputId": "34fb392e-0501-4248-f85d-abf603cdae8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  spam.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXVQCF-ovo4G",
        "colab_type": "text"
      },
      "source": [
        "There are two columns: `v1` -- spam or ham indicator, `v2` -- text of the message."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiKE89v0zMiY",
        "colab_type": "code",
        "outputId": "c515d6f9-a47d-4172-be33-0ae06fb3e8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"spam.csv\", usecols=[\"v1\", \"v2\"], encoding='latin-1')\n",
        "# 1 - spam, 0 - ham\n",
        "df.v1 = (df.v1 == \"spam\").astype(\"int\")\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   v1                                                 v2\n",
              "0   0  Go until jurong point, crazy.. Available only ...\n",
              "1   0                      Ok lar... Joking wif u oni...\n",
              "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   0  U dun say so early hor... U c already then say...\n",
              "4   0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXQhTzrCv-Nk",
        "colab_type": "text"
      },
      "source": [
        "Your task is to split the data to train/dev/test. Make sure that each row appears only in one of the splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKXwdEDWh1vQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels= df['v1'].to_numpy()\n",
        "raw_content=df['v2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga5Qydpw-gdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0.15 for val, 0.15 for test, 0.7 for train\n",
        "val_size = int(df.shape[0] * 0.15)\n",
        "test_size = int(df.shape[0] * 0.15)\n",
        "\n",
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\"\n",
        "\n",
        "train_size= int(df.shape[0]*0.7)\n",
        "\n",
        "train_texts, train_labels = raw_content[:train_size],labels[:train_size]\n",
        "val_texts, val_labels     = raw_content[train_size:train_size+val_size],labels[train_size:train_size+val_size]\n",
        "test_texts, test_labels   = raw_content[-test_size:],labels[-test_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtf9KJnuqAPm",
        "colab_type": "code",
        "outputId": "b7276349-fef7-4b2b-c20b-949daea95dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"text: \", train_texts[0])\n",
        "print(\"Lables: \", train_labels[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text:  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "Lables:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGyHG4lBISP2",
        "colab_type": "text"
      },
      "source": [
        "## Data Processing\n",
        "\n",
        "The task is to create bag-of-words features: tokenize the text, index each token, represent the sentence as a dictionary of tokens and their counts, limit the vocabulary to $n$ most frequent tokens. In the lab we use built-in `sklearn` function, `sklearn.feature_extraction.text.CountVectorizer`. \n",
        "**In this HW, you are required to implement the `Vectorizer` on your own without using `sklearn` built-in functions.**\n",
        "\n",
        "Function `preprocess_data` takes the list of texts and returns list of (lists of tokens). \n",
        "You may use [spacy](https://spacy.io/) or [nltk](https://www.nltk.org/) text processing libraries in `preprocess_data` function. \n",
        "\n",
        "Class `Vectorizer` is used to vectorize the text and to create a matrix of features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTzKgsNPw7nD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9bfbbcd2-c976-438e-b816-2bfc1e488e41"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import word_tokenize,sent_tokenize"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "793EFaQYhHeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(data):\n",
        "    # This function should return a list of lists of preprocessed tokens for each message\n",
        "    \"\"\"\n",
        "    YOUR CODE GOES HERE\n",
        "    \"\"\"\n",
        "    preprocessed_data = []\n",
        "\n",
        "    for words in data:\n",
        "      tokens=nltk.word_tokenize(words)\n",
        "      #for a in tokens:\n",
        "      preprocessed_data.append(tokens) \n",
        "         \n",
        "    return preprocessed_data\n",
        "\n",
        "train_data = preprocess_data(train_texts)\n",
        "val_data = preprocess_data(val_texts)\n",
        "test_data = preprocess_data(test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brWrWtRk0jaa",
        "colab_type": "code",
        "outputId": "8852f1c4-0f7d-4547-f598-90a6e1b428ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "## Double check how it looks like\n",
        "train_data[:2]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Go',\n",
              "  'until',\n",
              "  'jurong',\n",
              "  'point',\n",
              "  ',',\n",
              "  'crazy..',\n",
              "  'Available',\n",
              "  'only',\n",
              "  'in',\n",
              "  'bugis',\n",
              "  'n',\n",
              "  'great',\n",
              "  'world',\n",
              "  'la',\n",
              "  'e',\n",
              "  'buffet',\n",
              "  '...',\n",
              "  'Cine',\n",
              "  'there',\n",
              "  'got',\n",
              "  'amore',\n",
              "  'wat',\n",
              "  '...'],\n",
              " ['Ok', 'lar', '...', 'Joking', 'wif', 'u', 'oni', '...']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM2qpOKpjVbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class Vectorizer():\n",
        "    def __init__(self, max_features):\n",
        "        self.max_features = max_features\n",
        "        self.vocab_list = None\n",
        "        self.token_to_index = None\n",
        "\n",
        "    def fit(self, dataset):\n",
        "        # Create a vocab list, self.vocab_list, using the most frequent \"max_features\" tokens\n",
        "        # Create a token indexer, self.token_to_index, that will return index of the token in self.vocab\n",
        "        \"\"\"\n",
        "        YOUR CODE GOES HERE\n",
        "        \"\"\"\n",
        "        all_tokens= []\n",
        "        NOTINLIST=0\n",
        "        for words in dataset:\n",
        "          for token in words:\n",
        "            all_tokens.append(token)\n",
        "        pass\n",
        "        token_counter = Counter(all_tokens)\n",
        "        vocab, count = zip(*token_counter.most_common(self.max_features))\n",
        "        self.token_to_index = dict(zip(vocab, range(1,1+len(vocab)))) \n",
        "        self.token_to_index[\"<strangeword>\"] = NOTINLIST\n",
        "        self.vocab_list = [\"<strangeword>\"]+ list(vocab)\n",
        "\n",
        "    def transform(self, dataset):\n",
        "        # This function transforms text dataset into a matrix, data_matrix\n",
        "        \"\"\"\n",
        "        YOUR CODE GOES HERE\n",
        "        \"\"\"\n",
        "        data_matrix = np.zeros((len(dataset), len(self.vocab_list)))\n",
        "       \n",
        "        for i in range(len(dataset)):\n",
        "          words = dataset[i]\n",
        "          for token in words:\n",
        "            if token in self.token_to_index:\n",
        "              j = self.token_to_index[token]\n",
        "            else:\n",
        "              j = self.token_to_index[\"<strangeword>\"]\n",
        "            data_matrix[i,j] += 1\n",
        "       \n",
        "        return data_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXMrZXlZjcH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 2000 # TODO: Replace None with a number\n",
        "vectorizer = Vectorizer(max_features=max_features)\n",
        "vectorizer.fit(train_data)\n",
        "X_train = vectorizer.transform(train_data)\n",
        "X_val = vectorizer.transform(val_data)\n",
        "X_test = vectorizer.transform(test_data)\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "vocab = vectorizer.vocab_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGLg6udky1zo",
        "colab_type": "text"
      },
      "source": [
        "You can add more features to the feature matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s80GgEm6F5DG",
        "colab_type": "code",
        "outputId": "77182247-5e25-409c-c828-14975f153686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\"\n",
        "## We can take the counts of the tokens in one sentence as one of the festures: pseudo code as below\n",
        "\"\"\"\n",
        " data_matrix = np.zeros((len(dataset), len(self.vocab_list)))\n",
        "       \n",
        "        for i in range(len(dataset)):\n",
        "          words = dataset[i]\n",
        "          for token in words:\n",
        "            data matrix = len(token)\n",
        "       \n",
        "        return data_matrix\n",
        "\"\"\""
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nYOUR CODE GOES HERE\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtm7a6JWu9-3",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "We train logistic regression model and save prediction for train, val and test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq9stSAbAIZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define Logistic Regression model\n",
        "model = LogisticRegression(random_state=0, solver='liblinear')\n",
        "\n",
        "# Fit the model to training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make prediction using the trained model\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j-Abw7JOqD_",
        "colab_type": "text"
      },
      "source": [
        "## Performance of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akg9LvP5DGE8",
        "colab_type": "text"
      },
      "source": [
        "Your task is to report train, val, test accuracies and F1 scores.\n",
        "**You are required to implement `accuracy_score` and `f1_score` methods without using built-in python functions.**\n",
        "\n",
        "Your model should achieve at least **0.95** test accuracy and **0.90** test F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chqVbKH6kZyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_score(y_true, y_pred): \n",
        "    # Calculate accuracy of the model's prediction\n",
        "    \"\"\"\n",
        "    YOUR CODE GOES HERE\n",
        "    \"\"\"\n",
        "    accuracy = sum(y_true==y_pred)/y_pred.shape[0]\n",
        "    return accuracy\n",
        "\n",
        "def f1_score(y_true, y_pred): \n",
        "    # Calculate F1 score of the model's prediction\n",
        "    \"\"\"\n",
        "    YOUR CODE GOES HERE\n",
        "    \"\"\"\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_pred)): \n",
        "        if y_true[i]==y_pred[i]==1:\n",
        "           TP += 1\n",
        "        if y_pred[i]==1 and y_true[i]!=y_pred[i]:\n",
        "           FP += 1\n",
        "        if y_true[i]==y_pred[i]==0:\n",
        "           TN += 1\n",
        "        if y_pred[i]==0 and y_true[i]!=y_pred[i]:\n",
        "           FN += 1\n",
        "\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqrMw0udDD04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "27b3d8a7-31ee-4d63-dbfe-2fd8333050ac"
      },
      "source": [
        "print(f\"Training accuracy: {accuracy_score(y_train, y_train_pred):.3f}, \"\n",
        "      f\"F1 score: {f1_score(y_train, y_train_pred):.3f}\")\n",
        "print(f\"Validation accuracy: {accuracy_score(y_val, y_val_pred):.3f}, \"\n",
        "      f\"F1 score: {f1_score(y_val, y_val_pred):.3f}\")\n",
        "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.3f}, \"\n",
        "      f\"F1 score: {f1_score(y_test, y_test_pred):.3f}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.995, F1 score: 0.982\n",
            "Validation accuracy: 0.977, F1 score: 0.916\n",
            "Test accuracy: 0.983, F1 score: 0.934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW7P84giGgP4",
        "colab_type": "text"
      },
      "source": [
        "**Question.**\n",
        "Is accuracy the metric that logistic regression optimizes while training? If no, which metric is optimized in logistic regression?\n",
        "\n",
        "**Your answer:** \n",
        "Yes, there are two ways one is the cross entropy loss which is to minimize the loss function, another is by using Gradient Descent way. In here, it is obvioulsy used cross entroy as the loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak0h71krLPqX",
        "colab_type": "text"
      },
      "source": [
        "**Question.**\n",
        "In general, does having 0.99 accuracy on test means that the model is great? If no, can you give an example of a case when the accuracy is high but the model is not good? (Hint: why do we use F1 score?)\n",
        "\n",
        "**Your answer:** Nope,0.99 accuracy seems good. However, it is depends on the situation. When thinking of the corona Virus, we do care more about the Fasle negative, because we do not want someone who is sick and carrying a virus that can spread very quickly. That is why we use F1 in here, rather than. just the accuracy.\n",
        "Similarly, in sick patient detection. If a sick patient (Actual Positive) goes through the test and predicted as not sick (Predicted Negative). The cost associated with False Negative will be extremely high if the sickness is contagious.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_RDI0qdOxwM",
        "colab_type": "text"
      },
      "source": [
        "### Exploration of predicitons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHR2OqYCDOxs",
        "colab_type": "text"
      },
      "source": [
        "Show a few examples with true+predicted labels on the train and val sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yv8GD-UGXvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "39ebaf95-d204-47e1-98e8-dd5ecc11b58e"
      },
      "source": [
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\"\n",
        "# 1 - spam, 0 - ham\n",
        "print(\"First 15 training labels:\",\"predictions: \",y_train_pred[:15],\" truth: \",y_train[:15])\n",
        "print(\"First 15 validation labels:\",\"predictions: \",y_val_pred[:15],\" truth: \",y_val[:15])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 15 training labels: predictions:  [0 0 1 0 0 1 0 0 1 1 0 1 1 0 0]  truth:  [0 0 1 0 0 1 0 0 1 1 0 1 1 0 0]\n",
            "First 15 validation labels: predictions:  [0 0 0 1 1 0 0 0 0 0 0 1 0 0 0]  truth:  [0 0 0 1 1 0 0 0 0 0 0 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neMQ4VR9GVL3",
        "colab_type": "text"
      },
      "source": [
        "**Question** Print 10 examples from val set which were labeled incorrectly by the model. Why do you think the model got them wrong?\n",
        "\n",
        "**Your answer:** Nope, becasue the bag of words does not care about the sequences of the words, thus the results showed that the labled is incorrected does not means that the model is wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QNbeOl9_hZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import Series,DataFrame\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ssK0jRxGY3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "af13b757-3f70-43ae-8e70-bb113b2fa5ce"
      },
      "source": [
        "\"\"\"\n",
        "YOUR CODE GOES HERE\n",
        "\"\"\"\n",
        "print(\"text:\", val_texts[y_val_pred != y_val][:][:10])\n",
        "print(\"Pred:\", y_val_pred[y_val_pred != y_val][:10])\n",
        "print(\"True:\", y_val[y_val_pred != y_val][:10])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: 3979                                   ringtoneking 84484\n",
            "4014    You will be receiving this week's Triple Echo ...\n",
            "4045      Win a å£1000 cash prize or a prize worth å£5000\n",
            "4067    TBS/PERSOLVO. been chasing us since Sept forå£...\n",
            "4142    In The Simpsons Movie released in July 2007 na...\n",
            "4211    Missed call alert. These numbers called but le...\n",
            "4247    accordingly. I repeat, just text the word ok o...\n",
            "4328    1Apple/Day=No Doctor. 1Tulsi Leaf/Day=No Cance...\n",
            "4392    RECPT 1/3. You have ordered a Ringtone. Your o...\n",
            "4471      3. You have received your mobile content. Enjoy\n",
            "Name: v2, dtype: object\n",
            "Pred: [0 0 0 0 0 0 0 1 0 0]\n",
            "True: [1 1 1 1 1 1 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja1hoUIFp_C2",
        "colab_type": "text"
      },
      "source": [
        "## End of Part 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tStaEcECey0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}