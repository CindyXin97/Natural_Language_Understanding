{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of  HW1 Part2. Spam Classification with LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6130709503c441ada5924454b21962fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d5b47f5578e54a60a2cf4e03f61e99cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_93a09f8f566c4a46bcf55c42a6738829",
              "IPY_MODEL_4c135be4813e4a36a08fd82cae5f183f"
            ]
          }
        },
        "8617a1be410448b680dbba504caf8d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d5d08dfa61d4bda9c9c35f5ed0edb4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6b83ad72fb4540d780c6520ae96697cf",
              "IPY_MODEL_64cbe429d50544608e64313cb8bfc5d7"
            ]
          }
        },
        "83635036151241c4ac672aa5a854c9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f13aa6a297604db694c3c1c142da909c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b7bcb63c3eb746ae885a3241ecbbc2b9",
              "IPY_MODEL_3ad9bb9267ad4e629bfd80eac3bb017b"
            ]
          }
        },
        "37d7a7777dc246ceabac9336f392570c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f7ea5df1af7d4e0d8bea8cbf37f280eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ba700d613e464d1abd64902bab76394a",
              "IPY_MODEL_00a895714e3440c9a8341244f19b8263"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBnmbg-jdztQ",
        "colab_type": "text"
      },
      "source": [
        "# Spam Classification Part 2\n",
        "\n",
        "The deadline for Part 1 is **2 pm Feb 19, 2020**.   \n",
        "You should submit a `.ipynb` file with your solutions to NYU Classes.\n",
        "\n",
        "---\n",
        "\n",
        "In this homework, we will reuse the spam prediction dataset used in HW1-Part1.\n",
        "We will use a word-level BiLSTM sentence encoder to encode the sentence and a neural network classifier.\n",
        "\n",
        "For reference, you may read [this paper](https://arxiv.org/abs/1705.02364).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKJv-b6RewJn",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading\n",
        "First, reuse the code from HW1-Part1 to download and read the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoiahW1_fZ6p",
        "colab_type": "code",
        "outputId": "42c322cb-61b5-402c-a2ee-5e924a905ae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "!wget 'https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR' -O spam.csv"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 05:14:57--  https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.142.100, 74.125.142.113, 74.125.142.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.142.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-04-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qap544l8kcgf7qqecoi3j6kukdq0n4um/1582088400000/08752484438609855375/*/1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-02-19 05:14:57--  https://doc-14-04-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qap544l8kcgf7qqecoi3j6kukdq0n4um/1582088400000/08752484438609855375/*/1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR?e=download\n",
            "Resolving doc-14-04-docs.googleusercontent.com (doc-14-04-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to doc-14-04-docs.googleusercontent.com (doc-14-04-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 503663 (492K) [text/csv]\n",
            "Saving to: ‘spam.csv’\n",
            "\n",
            "\rspam.csv              0%[                    ]       0  --.-KB/s               \rspam.csv            100%[===================>] 491.86K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2020-02-19 05:14:57 (143 MB/s) - ‘spam.csv’ saved [503663/503663]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I52OxyBgfi_j",
        "colab_type": "code",
        "outputId": "3866a750-abfb-490c-fe9a-5190fc2f7714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"spam.csv\", usecols=[\"v1\", \"v2\"], encoding='latin-1')\n",
        "# 1 - spam, 0 - ham\n",
        "df.v1 = (df.v1 == \"spam\").astype(\"int\")\n",
        "df.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   v1                                                 v2\n",
              "0   0  Go until jurong point, crazy.. Available only ...\n",
              "1   0                      Ok lar... Joking wif u oni...\n",
              "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   0  U dun say so early hor... U c already then say...\n",
              "4   0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCihb3oogn27",
        "colab_type": "text"
      },
      "source": [
        "We will split the data into train, val, and test sets.  \n",
        "`train_texts`, `val_texts`, and `test_texts` should contain a list of text examples in the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H78E3FLgEA2",
        "colab_type": "code",
        "outputId": "9c5f04f4-70f8-4ff4-b4f4-c437e8a72455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# 0.15 for val, 0.15 for test, 0.7 for train\n",
        "val_size = int(df.shape[0] * 0.15)\n",
        "test_size = int(df.shape[0] * 0.15)\n",
        "\n",
        "# Shuffle the data\n",
        "df = df.sample(frac=1)\n",
        "# Split df to test/val/train\n",
        "test_df = df[:test_size]\n",
        "val_df = df[test_size:test_size+val_size]\n",
        "train_df = df[test_size+val_size:]\n",
        "\n",
        "\n",
        "train_texts, train_labels = list(train_df.v2), list(train_df.v1)\n",
        "val_texts, val_labels     = list(val_df.v2), list(val_df.v1)\n",
        "test_texts, test_labels   = list(test_df.v2), list(test_df.v1)\n",
        "\n",
        "\n",
        "# Check that idces do not overlap\n",
        "assert set(train_df.index).intersection(set(val_df.index)) == set({})\n",
        "assert set(test_df.index).intersection(set(train_df.index)) == set({})\n",
        "assert set(val_df.index).intersection(set(test_df.index)) == set({})\n",
        "# Check that all idces are present\n",
        "assert df.shape[0] == len(train_labels) + len(val_labels) + len(test_labels)\n",
        "\n",
        "# Sizes\n",
        "print(\n",
        "    f\"Size of initial data: {df.shape[0]}\\n\"\n",
        "    f\"Train size: {len(train_labels)}\\n\"\n",
        "    f\"Val size: {len(val_labels)}\\n\"\n",
        "    f\"Test size: {len(test_labels)}\\n\"\n",
        ")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of initial data: 5572\n",
            "Train size: 3902\n",
            "Val size: 835\n",
            "Test size: 835\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX8D130ngVxu",
        "colab_type": "code",
        "outputId": "bcf2693c-9ad6-45ce-f9c6-2890057a8c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train_texts[:10] # Just checking the examples in train_text"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Goodmorning, Today i am late for  &lt;#&gt; min.',\n",
              " 'Did you say bold, then torch later. Or one torch and 2bold?',\n",
              " 'Babe ? I lost you ... Will you try rebooting ?',\n",
              " 'Yup... Hey then one day on fri we can ask miwa and jiayin take leave go karaoke ',\n",
              " 'Not sure I have the stomach for it ...',\n",
              " 'Does not operate after  &lt;#&gt;  or what',\n",
              " 'Hey... Why dont we just go watch x men and have lunch... Haha ',\n",
              " 'No message..no responce..what happend?',\n",
              " 'Oh ok..',\n",
              " 'Yo come over carlos will be here soon']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sm_iuR_hJp2",
        "colab_type": "text"
      },
      "source": [
        "# Download and Load GloVe Embeddings\n",
        "We will use GloVe embeddings as our word representations.  \n",
        "Let's download and load glove. We will reuse the code from Lab 2 for downloading and loading GloVe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRCcCtcSjEPR",
        "colab_type": "code",
        "outputId": "5ebf8231-aa62-4c87-ab60-54abdbeca75e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Download GloVe word embeddings\n",
        "\n",
        "# === Download GloVe word embeddings\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "# === Unzip word embeddings and use only the top 50000 word embeddings for speed\n",
        "# !unzip glove.6B.zip\n",
        "# !head -n 50000 glove.6B.300d.txt > glove.6B.300d__50k.txt\n",
        "\n",
        "# === Download Preprocessed version\n",
        "!wget https://docs.google.com/uc?id=1KMJTagaVD9hFHXFTPtNk0u2JjvNlyCAu -O glove_split.aa\n",
        "!wget https://docs.google.com/uc?id=1LF2yD2jToXriyD-lsYA5hj03f7J3ZKaY -O glove_split.ab\n",
        "!wget https://docs.google.com/uc?id=1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f -O glove_split.ac\n",
        "!cat glove_split.?? > 'glove.6B.300d__50k.txt'"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 05:14:58--  https://docs.google.com/uc?id=1KMJTagaVD9hFHXFTPtNk0u2JjvNlyCAu\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.20.139, 74.125.20.138, 74.125.20.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0k-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mvc5p81k1tt3q3iv0dabfatoae90qcqo/1582089300000/14514704803973256873/*/1KMJTagaVD9hFHXFTPtNk0u2JjvNlyCAu [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-02-19 05:15:00--  https://doc-0k-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mvc5p81k1tt3q3iv0dabfatoae90qcqo/1582089300000/14514704803973256873/*/1KMJTagaVD9hFHXFTPtNk0u2JjvNlyCAu\n",
            "Resolving doc-0k-0g-docs.googleusercontent.com (doc-0k-0g-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to doc-0k-0g-docs.googleusercontent.com (doc-0k-0g-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [audio/audible]\n",
            "Saving to: ‘glove_split.aa’\n",
            "\n",
            "glove_split.aa          [   <=>              ]  50.00M  50.1MB/s    in 1.0s    \n",
            "\n",
            "2020-02-19 05:15:01 (50.1 MB/s) - ‘glove_split.aa’ saved [52428800]\n",
            "\n",
            "--2020-02-19 05:15:02--  https://docs.google.com/uc?id=1LF2yD2jToXriyD-lsYA5hj03f7J3ZKaY\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.20.100, 74.125.20.102, 74.125.20.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-08-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9ro4vbk351rebcrn303gld75810r02s6/1582089300000/14514704803973256873/*/1LF2yD2jToXriyD-lsYA5hj03f7J3ZKaY [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-02-19 05:15:06--  https://doc-08-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9ro4vbk351rebcrn303gld75810r02s6/1582089300000/14514704803973256873/*/1LF2yD2jToXriyD-lsYA5hj03f7J3ZKaY\n",
            "Resolving doc-08-0g-docs.googleusercontent.com (doc-08-0g-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to doc-08-0g-docs.googleusercontent.com (doc-08-0g-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘glove_split.ab’\n",
            "\n",
            "glove_split.ab          [  <=>               ]  50.00M   157MB/s    in 0.3s    \n",
            "\n",
            "2020-02-19 05:15:07 (157 MB/s) - ‘glove_split.ab’ saved [52428800]\n",
            "\n",
            "--2020-02-19 05:15:07--  https://docs.google.com/uc?id=1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.20.139, 74.125.20.138, 74.125.20.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/vca72eo0itn0s6m61ukbfgnmm01q32u6/1582089300000/14514704803973256873/*/1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-02-19 05:15:09--  https://doc-04-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/vca72eo0itn0s6m61ukbfgnmm01q32u6/1582089300000/14514704803973256873/*/1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f\n",
            "Resolving doc-04-0g-docs.googleusercontent.com (doc-04-0g-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to doc-04-0g-docs.googleusercontent.com (doc-04-0g-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘glove_split.ac’\n",
            "\n",
            "glove_split.ac          [ <=>                ]  23.49M   134MB/s    in 0.2s    \n",
            "\n",
            "2020-02-19 05:15:10 (134 MB/s) - ‘glove_split.ac’ saved [24629432]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AfN4rYTOmCD",
        "colab_type": "text"
      },
      "source": [
        "## Load GloVe Embeddings\n",
        "\n",
        "We are going to reuse the code from Lab 2 here. In addition, we will add a padding token and an unknown token to our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSF0C4jHjnSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_glove(glove_path, embedding_dim):\n",
        "    with open(glove_path) as f:\n",
        "        token_ls = [PAD_TOKEN, UNK_TOKEN]\n",
        "        embedding_ls = [np.zeros(embedding_dim), np.random.rand(embedding_dim)]\n",
        "        for line in f:\n",
        "            token, raw_embedding = line.split(maxsplit=1)\n",
        "            token_ls.append(token)\n",
        "            embedding = np.array([float(x) for x in raw_embedding.split()])\n",
        "            embedding_ls.append(embedding)\n",
        "        embeddings = np.array(embedding_ls)\n",
        "    return token_ls, embeddings\n",
        "\n",
        "PAD_TOKEN = '<PAD>'\n",
        "UNK_TOKEN = '<UNK>'\n",
        "EMBEDDING_DIM=300 # dimension of Glove embeddings\n",
        "glove_path = \"glove.6B.300d__50k.txt\"\n",
        "vocab, embeddings = load_glove(glove_path, EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_VZkGbgO4yA",
        "colab_type": "text"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpbnKsQeptXw",
        "colab_type": "code",
        "outputId": "ac24950a-ccec-41fa-923a-9bcdd2703226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "!pip install sacremoses\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import sacremoses\n",
        "from torch.utils.data import dataloader, Dataset\n",
        "import tqdm"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.38)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wwy3gSvO87p",
        "colab_type": "text"
      },
      "source": [
        "# Featurize text data.\n",
        "We will reuse the `featurize` function from Lab 2 to convert text data into features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1aLbeOBmRyR",
        "colab_type": "code",
        "outputId": "346b19ac-8d75-43fc-fc79-23848a266e34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "6130709503c441ada5924454b21962fb",
            "8617a1be410448b680dbba504caf8d27",
            "83635036151241c4ac672aa5a854c9d2"
          ]
        }
      },
      "source": [
        "def featurize(data, labels, tokenizer, vocab, max_seq_length=128):\n",
        "    vocab_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "    text_data = []\n",
        "    label_data = []\n",
        "    for ex in tqdm.tqdm_notebook(data):\n",
        "        tokenized = tokenizer.tokenize(ex.lower())\n",
        "        ids = [vocab_to_idx.get(token, 1) for token in tokenized]\n",
        "        text_data.append(ids)\n",
        "    return text_data, labels\n",
        "tokenizer = sacremoses.MosesTokenizer()\n",
        "train_data_indices, train_labels = featurize(train_texts, train_labels, tokenizer, vocab)\n",
        "val_data_indices, val_labels = featurize(val_texts, val_labels, tokenizer, vocab)\n",
        "test_data_indices, test_labels = featurize(test_texts, test_labels, tokenizer, vocab)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6130709503c441ada5924454b21962fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=3902), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8617a1be410448b680dbba504caf8d27",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=835), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83635036151241c4ac672aa5a854c9d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=835), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEF48Bddt5kA",
        "colab_type": "code",
        "outputId": "a7511460-0ccd-47ce-f978-775a12196b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "print(\"\\nTrain text first 5 examples:\\n\", train_data_indices[:5])\n",
        "print(\"\\nTrain labels first 5 examples:\\n\", train_labels[:5])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train text first 5 examples:\n",
            " [[1, 3, 375, 43, 915, 290, 12, 725, 18811, 91, 2751, 725, 16537, 91, 10373, 4], [121, 83, 205, 6700, 3, 129, 8640, 1, 48, 50, 8640, 7, 1, 190], [15114, 190, 43, 404, 83, 436, 45, 83, 843, 1, 190], [1, 436, 7944, 129, 50, 124, 15, 18132, 55, 88, 1714, 1, 7, 1, 192, 893, 244, 22408], [38, 1087, 43, 35, 2, 7465, 12, 22, 436]]\n",
            "\n",
            "Train labels first 5 examples:\n",
            " [0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dlUYNvgPUXs",
        "colab_type": "text"
      },
      "source": [
        "# Create DataLoaders\n",
        " Now, let's create pytorch DataLoaders for our train, val, and test data.\n",
        " You can reference Lab 2.\n",
        "\n",
        " `SpamDataset` class is similar to `TextDataset` from Lab 2. But it has an additional parameter called `self.max_sent_length` and a `spam_collate_func`.  \n",
        "\n",
        "`spam_collate_func` is supposed to dynamically pad or trim the sentences in the batch based on `self.max_sent_length` and the length of longest sequence in the batch.\n",
        "- If `self.max_sent_length` is greater than the length of longest sequence in the batch, use `self.max_sent_length`. Otherwise, use the length of longest sequence in the batch.\n",
        "- We do this because sometimes, our input sentences in the batch may be much shorter than `self.max_sent_length`.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uJDfnVMxBsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
        "    Note that this class inherits torch.utils.data.Dataset\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, data_list, target_list, max_sent_length=128):\n",
        "        \"\"\"\n",
        "        @param data_list: list of data tokens \n",
        "        @param target_list: list of data targets \n",
        "\n",
        "        \"\"\"\n",
        "        self.data_list = data_list\n",
        "        self.target_list = target_list\n",
        "        self.max_sent_length = max_sent_length\n",
        "        assert (len(self.data_list) == len(self.target_list))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "        \n",
        "    def __getitem__(self, key, max_sent_length=None):\n",
        "        \"\"\"\n",
        "        Triggered when you call dataset[i]\n",
        "        \"\"\"\n",
        "        if max_sent_length is None:\n",
        "            max_sent_length = self.max_sent_length\n",
        "        token_idx = self.data_list[key][:max_sent_length]\n",
        "        label = self.target_list[key]\n",
        "        return [token_idx, label]\n",
        "\n",
        "    def spam_collate_func(self,batch):\n",
        "        \"\"\"\n",
        "        Customized function for DataLoader that dynamically pads the batch so that all \n",
        "        data have the same length\n",
        "        \"\"\" \n",
        "        data_list = [] # store padded sequences\n",
        "        label_list = []\n",
        "        max_batch_seq_len = None # the length of longest sequence in batch\n",
        "                                 # if it is less than self.max_sent_length.\n",
        "                                 # else max_batch_seq_len = self.max_sent_length\n",
        "\n",
        "        \"\"\"\n",
        "          # Pad the sequences in your data \n",
        "          # if their length is less than max_batch_seq_len\n",
        "          # or trim the sequences that are longer than self.max_sent_length\n",
        "          # return padded data_list and label_list\n",
        "          1. TODO: Your code here \n",
        "        \"\"\"\n",
        "        \n",
        "        length_list = []\n",
        "        for seq in batch:\n",
        "          label_list.append(seq[1])\n",
        "          length_list.append(len(seq[0]))\n",
        "\n",
        "        if max(length_list) < self.max_sent_length:\n",
        "          max_batch_seq_len = max(length_list)\n",
        "        else:\n",
        "          max_batch_seq_len = self.max_sent_length\n",
        "\n",
        "        for seq in batch:\n",
        "          pad_vec = np.pad(np.array(seq[0]), \n",
        "                                pad_width=((0,max_batch_seq_len - len(seq[0]))), \n",
        "                                mode=\"constant\", constant_values=0)\n",
        "          data_list.append(pad_vec)\n",
        "        \n",
        "        return [torch.from_numpy(np.array(data_list)), torch.LongTensor(label_list)]\n",
        "\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "max_sent_length=128\n",
        "train_dataset = SpamDataset(train_data_indices, train_labels, max_sent_length)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=train_dataset.spam_collate_func,\n",
        "                                           shuffle=True)\n",
        "\n",
        "val_dataset = SpamDataset(val_data_indices, val_labels, train_dataset.max_sent_length)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=train_dataset.spam_collate_func,\n",
        "                                           shuffle=False)\n",
        "\n",
        "test_dataset = SpamDataset(test_data_indices, test_labels, train_dataset.max_sent_length)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=train_dataset.spam_collate_func,\n",
        "                                           shuffle=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWgRGaCWf4Zz",
        "colab_type": "text"
      },
      "source": [
        "Let's try to print out an example batch from train_loader.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O8R_KhwxULI",
        "colab_type": "code",
        "outputId": "9cda488e-5542-4d47-cc91-bed9065f804f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data_batch, labels = next(iter(train_loader))\n",
        "print(\"data batch dimension: \", data_batch.size())\n",
        "print(\"data_batch: \", data_batch)\n",
        "print(\"labels: \", labels)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data batch dimension:  torch.Size([64, 74])\n",
            "data_batch:  tensor([[  43,   45,  255,  ...,    0,    0,    0],\n",
            "        [2413,  807,  582,  ...,    0,    0,    0],\n",
            "        [ 888,  287,  348,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 305,    6, 1547,  ...,    0,    0,    0],\n",
            "        [ 199,   61,  883,  ...,    0,    0,    0],\n",
            "        [  83, 3805,  194,  ...,    0,    0,    0]])\n",
            "labels:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpdnYbPIgNXw",
        "colab_type": "text"
      },
      "source": [
        "# Build a BiLSTM Classifier\n",
        "\n",
        "Now we are going to build a BiLSTM classifier. Check this [blog post](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) and [`torch.nn.LSTM`](https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM) for reference.  \n",
        "\n",
        "The hyperparameters for LSTM are already given, but I did not do hyperparameter tuning. You should get a good accuracy with these hyperparameters but you may try to tune the hyperparameters and use different hyperparameters to get better performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOYEmADNDVIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First import torch related libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTMClassifier classification model\n",
        "    \"\"\"\n",
        "    def __init__(self, embeddings, hidden_size, num_layers, num_classes, bidirectional, dropout_prob=0.3):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = self.load_pretrained_embeddings(embeddings)\n",
        "        self.dropout = None\n",
        "        self.lstm = None\n",
        "        self.non_linearity = None # For example, ReLU\n",
        "        self.clf = None # classifier layer\n",
        "        \"\"\"\n",
        "           define the components of your BiLSTM Classifier model\n",
        "           You may refer to Lab2 for reference\n",
        "           2. TODO: Your code here\n",
        "        \"\"\"\n",
        "        self.embedding_layer = self.load_pretrained_embeddings(embeddings)\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "        self.lstm = nn.LSTM(input_size=len(embeddings[1]),#The number of expected features in the input x\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, #Number of recurrent layers.\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True\n",
        "                           )\n",
        "        self.non_linearity = nn.ReLU() # For example, ReLU\n",
        "        self.clf =nn.Linear(hidden_size,num_classes)\n",
        "        pass\n",
        "    \n",
        "    def load_pretrained_embeddings(self, embeddings):\n",
        "        \"\"\"\n",
        "           The code for loading embeddings from Lab 2\n",
        "           Unlike lab, we are not setting `embedding_layer.weight.requires_grad = False`\n",
        "           because we want to finetune the embeddings on our data\n",
        "        \"\"\"\n",
        "        embedding_layer = nn.Embedding(embeddings.shape[0], embeddings.shape[1], padding_idx=0)\n",
        "        embedding_layer.weight.data = torch.Tensor(embeddings).float()\n",
        "        return embedding_layer\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        logits = None\n",
        "        \"\"\"\n",
        "           Write forward pass for LSTM\n",
        "           Example, forward:= embedding -> bilstm -> pooling (sum?mean?max?) \n",
        "                              nonlinearity -> classifier\n",
        "           Refer to: https://arxiv.org/abs/1705.02364 \n",
        "           Return logits\n",
        "           You may refer to Lab2 for embedding lookup and how to return logits\n",
        "           3. TODO: Your code here\n",
        "        \"\"\"\n",
        "\n",
        "        # output = self.embedding_layer(inputs)\n",
        "        # lstm_output,(h_n,c_n) = self.lstm(lstm_output)\n",
        "        \n",
        "\n",
        "        # # maxpooling\n",
        "        # forward = lstm_output[:,:,:hidden_size]\n",
        "        # backward = lstm_output[:,:,hidden_size:] \n",
        "        # output = torch.stack([forward,backward])\n",
        "        # output,_ = torch.max(output,dim=1)\n",
        "        # output,_ = torch.max(output,dim=0)\n",
        "\n",
        "        # output = self.non_linearity(output)\n",
        "        # logits = self.clf(output)\n",
        "\n",
        "        out = self.embedding_layer(inputs)\n",
        "        lstm_out,(h_n,c_n) = self.lstm(out)\n",
        "\n",
        "        # maxpooling\n",
        "        forward = lstm_out[:,:,:hidden_size]\n",
        "        backward = lstm_out[:,:,hidden_size:] \n",
        "        out = torch.stack([forward,backward])\n",
        "        out,_ = torch.max(out,dim=2)\n",
        "        out,_ = torch.max(out,dim=0)\n",
        "  # Add linear Classifier\n",
        "        out = self.non_linearity(out)\n",
        "        logits = self.clf(out)\n",
        "        return logits\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6P7O47Lfr0a",
        "colab_type": "text"
      },
      "source": [
        "First, we will define an evaluation function that will return the accuracy of the model. We will use this to compute validation accuracy and test accuracy of the model given a dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSkdBx1ULCFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "    accuracy = None\n",
        "    model.eval()\n",
        "    \"\"\"\n",
        "        4. TODO: Your code here\n",
        "        Calculate the accuracy of the model on the data in dataloader\n",
        "        You may refer to `run_inference` function from Lab2 \n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        for batch_text, batch_labels in dataloader:\n",
        "            preds = model(batch_text.to(device))\n",
        "            batch_labels = batch_labels.to(device)\n",
        "            all_preds.append(preds.detach().cpu().numpy())\n",
        "            all_labels.append(batch_labels)\n",
        "    predicted=np.concatenate(all_preds, axis=0)\n",
        "    label=np.concatenate(all_labels, axis=0)\n",
        "    accuracy=(np.array(label)==predicted.argmax(-1)).mean()\n",
        "    return accuracy \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpCXZCO7iuEL",
        "colab_type": "text"
      },
      "source": [
        "# Initialize the BiLSTM classifier model, criterion and optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaPW_CjlK0F7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BiLSTM hyperparameters\n",
        "hidden_size = 32\n",
        "num_layers = 1\n",
        "num_classes = 2\n",
        "bidirectional=True\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# if cuda exists, use cuda, else run on cpu\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "model = LSTMClassifier(embeddings, hidden_size, num_layers, num_classes, bidirectional)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwkHYzbQikT4",
        "colab_type": "text"
      },
      "source": [
        "# Train model with early stopping\n",
        "\n",
        "Train the model for `NUM_EPOCHS`. \n",
        "Keep track of training loss (just like we did in Lab 2).  \n",
        "Compute the validation accuracy after each epoch. Keep track of the best validation accuracy and save the model with the best validation accuracy.  \n",
        "\n",
        "If the validation accuracy does not improve for more than `early_stop_patience` times in a row, stop training. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOlop_TMOD9V",
        "colab_type": "code",
        "outputId": "bab5e332-9849-44ee-990d-4ec5e65e0919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "37d7a7777dc246ceabac9336f392570c"
          ]
        }
      },
      "source": [
        "train_loss_history = []\n",
        "val_accuracy_history = []\n",
        "best_val_accuracy = 0\n",
        "n_no_improve = 0\n",
        "early_stop_patience=2\n",
        "NUM_EPOCHS=10\n",
        "  \n",
        "for epoch in tqdm.tqdm_notebook(range(NUM_EPOCHS)):\n",
        "    model.train() # this enables regularization, which we don't currently have\n",
        "    for i, (data_batch, batch_labels) in enumerate(train_loader):\n",
        "        \"\"\"\n",
        "           Code for training lstm\n",
        "           Keep track of training of for each batch using train_loss_history\n",
        "        \"\"\"\n",
        "        preds = model(data_batch.to(device))\n",
        "        loss = criterion(preds, batch_labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss_history.append(loss.item())\n",
        "        \n",
        "    # The end of a training epoch \n",
        "\n",
        "    \"\"\"\n",
        "        Code for tracking best validation accuracy, saving the best model, and early stopping\n",
        "        # Compute validation accuracy after each training epoch using `evaluate` function\n",
        "        # Keep track of validation accuracy in `val_accuracy_history`\n",
        "        # save model with best validation accuracy, hint: torch.save(model, 'best_model.pt')\n",
        "        # Early stopping: \n",
        "        # stop training if the validation accuracy does not improve for more than `early_stop_patience` runs\n",
        "        5. TODO: Your code here\n",
        "    \"\"\"\n",
        "    accuracy = evaluate(model,test_loader,device)\n",
        "    val_accuracy_history.append(accuracy)\n",
        "    if accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = accuracy\n",
        "        torch.save(model, 'best_model.pt')\n",
        "    else:\n",
        "        n_no_improve += 1\n",
        "        print(\"epoch: \",n_no_improve, accuracy)\n",
        "        if n_no_improve > early_stop_patience:\n",
        "            print(\"Early stopping at:\", n_no_improve)\n",
        "            break  \n",
        "print(\"Best Validation Accuracy: \", best_val_accuracy)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37d7a7777dc246ceabac9336f392570c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type LSTMClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  1 0.9904191616766467\n",
            "epoch:  2 0.9880239520958084\n",
            "epoch:  3 0.98562874251497\n",
            "Early stopping at: 3\n",
            "Best Validation Accuracy:  0.9952095808383233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hhFpkMHnT7Z",
        "colab_type": "text"
      },
      "source": [
        "#Question: Why do we want to use early stopping?\n",
        "Your answer: Beacuse we we train the model, it is easy to cause the overfiting problem. Like the gradient descent. Early stopping rules can tell the models how many iterations can be run before the learner begins to over-fit. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I58rTeMEg05M",
        "colab_type": "text"
      },
      "source": [
        "# Draw training curve \n",
        "X-axis: training steps, Y-axis: training loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyalZo6tSXo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "faff9178-5f92-4161-8a52-c6ea78ed0404"
      },
      "source": [
        "pd.Series(train_loss_history).plot()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6810bb4e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMiI_u4ggvQK",
        "colab_type": "text"
      },
      "source": [
        "# Validation accuracy curve\n",
        "X-axis: Epochs, Y-axis: validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt8iNjFwPVtc",
        "colab_type": "code",
        "outputId": "aae3bad2-9f92-4100-9113-1a132edc491b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "pd.Series(val_accuracy_history).plot()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f68604767f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIEREJFMKCBERyZQCQkREMqWAEBGRTP0vrQCc4GgsNFAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqanG00Ggluj",
        "colab_type": "text"
      },
      "source": [
        "## You should expect to get test accuracy >= 95."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw6KtE2uSf1X",
        "colab_type": "code",
        "outputId": "65c40c4d-5bf5-4b1c-bd5c-ed721f4503ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reload best model from saved checkpoint\n",
        "# Compute test accuracy\n",
        "model = torch.load('best_model.pt')\n",
        "test_accuracy = evaluate(model, test_loader,device)\n",
        "print(test_accuracy)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9952095808383233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZsexYVPg6aq",
        "colab_type": "text"
      },
      "source": [
        "## Optional Bonus Questions: \n",
        "(If you scored full mark (total: 100) in all previous sections, you won't get additional marks so you probably won't need this. But you will get additional bonus marks for answering this if your score is below 100.)\n",
        "\n",
        "1. What are the problems with recurrent neural networks (RNNs) and how do we overcome them?\n",
        "Generally, for RNN, it has The Vanishing Gradient Problem, For instance, 1000 epochs might be enough to get the final weight for the time point t, but insufficient for training the weights for the time point t-3 due to a very low gradient at this point. Thus we can initialize weights so that the potential for vanishing gradient is minimized or use LSTM. In our case, when we try to guess what is the next words, RNN may not be able to analyze more sentences as the LSTM.\n",
        "\n",
        "\n",
        "\n",
        "2. What is the benefit of using the mean or max pooling of hidden states of LSTM instead of using the last hidden state of LSTM?\n",
        "Instead of using the last hidden layer which can not be fully trained, the average pooling is represented by all words contained; max pooling is represented by a small number of keywords and their salient features. Which will take all the sentences into consideration.\n",
        "## Answers:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AOUe92K_wBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}